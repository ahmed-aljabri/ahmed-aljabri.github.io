<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on AHMED AL-JABRI</title>
        <link>http://localhost:1313/posts/</link>
        <description>Recent content in Posts on AHMED AL-JABRI</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
        <lastBuildDate>Mon, 16 Dec 2024 11:46:21 +0000</lastBuildDate>
        <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Transport Layer Ossification</title>
            <link>http://localhost:1313/posts/tlo/</link>
            <pubDate>Mon, 16 Dec 2024 11:46:21 +0000</pubDate>
            
            <guid>http://localhost:1313/posts/tlo/</guid>
            <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I was first introduced to the ’Transport Layer Ossification’ (TLO) phenomenon when I watched a recorded
presentation by ex-google software engineer Jana Iyengar. In that session, the agenda was mainly around
QUIC, a new multiplexed transport protocol that was initially designed to enhance the web’s performance and
in particular HTTP. However QUIC later evolved to be an independent transport protocol that could support
other domains not just the web. Nevertheless, Jana started by highlighting some context before talking about
QUIC and in particular the challenges faced when attempting to deploy the Stream Control Transport Protocol
(SCTP), during that segment Jana explained how middleboxes are powerful enough that they have ossified the
transport layer making it near impossible to deploy new functional transport protocols. From there I became
curious to learn about TLO in depth, understand the direct implications on modern-day networks and the
potential workarounds.&lt;/p&gt;</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>I was first introduced to the ’Transport Layer Ossification’ (TLO) phenomenon when I watched a recorded
presentation by ex-google software engineer Jana Iyengar. In that session, the agenda was mainly around
QUIC, a new multiplexed transport protocol that was initially designed to enhance the web’s performance and
in particular HTTP. However QUIC later evolved to be an independent transport protocol that could support
other domains not just the web. Nevertheless, Jana started by highlighting some context before talking about
QUIC and in particular the challenges faced when attempting to deploy the Stream Control Transport Protocol
(SCTP), during that segment Jana explained how middleboxes are powerful enough that they have ossified the
transport layer making it near impossible to deploy new functional transport protocols. From there I became
curious to learn about TLO in depth, understand the direct implications on modern-day networks and the
potential workarounds.</p>
<blockquote>
<p>Note:
This post is not particularly about SCTP, QUIC or HTTP’s evolution to adopt QUIC,
I discuss the latter in more detail here. Alternatively, the context as to why these
technologies had to exist is what this blog post is all about.
It is also important to note that TLO is a subset of a more generic concept, Protocol Ossification which will be
described next to build our understanding of the topic of this post.</p>
</blockquote>
<h2 id="background">Background</h2>
<h3 id="21-context-on-protocol-ossification">2.1 Context on protocol ossification</h3>
<p>The general term Protocol Ossification refers to the increasing complexity of protocol innovation due to various
impairments imposed mainly by middlebox policies. In simpler terms, when a protocol becomes so ubiquitous
that it is almost practically impossible to replace or modify, we say that this protocol has been ’ossified’.</p>
<blockquote>
<p>Note:
A Middlebox as Lixia Zhang coined is a device that lies between communicating
endpoints that performs operations other than standard routing and forwarding.
Examples of such devices consist of proxies that make requests on your behalf by
rewriting packet headers, likewise NATs doing something similar to prevent your
direct exposure to the public internet. Additionally other types of middleboxes
enforce internal policies on passing traffic by striping certain TCP options and the
list goes on.</p>
</blockquote>
<p>To elaborate further on what protocol ossification phenomenon means or how it came to exist, it is helpful to
begin with some context.</p>
<p>Since the early days of IP networks, the end-to-end principle established the idea that diversity and intelligence
should lie at the network edge while the network core should simply be responsible for supporting IP routing
and forwarding operations. This entailed that when changes needed to happen whether to facilitate new
high level functionality or improve upon existing ones, only the communicating parties (end systems) need to
support this change. While on-path nodes simply provided basic networking functionality and hence don’t
need to be aware of it.</p>
<p><em>Figure 1: End-to-End Principle</em></p>
<p>Following this principle, it is critical to highlight that control resides with the network edge. In this sense
control refers to the ability to dictate and modify how host-to-host network exchanges should occur by
determining which protocols to use. As illustrated in figure 1, the on path systems simply operate up to the
network layer dealing with IP packets. Hence the end systems have full control of deciding which higher level
protocol to use, not to forget the ability to create new protocols as long as they are built on top of the IP protocol.
Nevertheless, today’s networks have evolved to become much more complex that what is illustrated above.
For instance if there was an update to the HTTP protocol, the support should only be needed to occur at the
Network edge (HTTP clients and servers) according to the end-to-end principle for this update to be functional.
With the existence of middleboxes however, that is no longer the case. What happens if a client decides to
use HTTP2 but their traffic is directed through a proxy that doesn’t support it? Tough luck, in that case the
client will have to do with HTTP 1.1 until the proxy supports the upgrade. Consequently, the existence of such
middleboxes introduces additional complexity when enhancing existing protocols or introducing new ones
since they also need to be aware of such changes.</p>
<p>In the example above with regards to the introduced complexity of enhancing HTTP, this is considered to be of
the lower end when it comes to the severity of this phenomenon. The severity of protocol ossification increases
as we traverse down the protocols stack towards the IP protocol. Based on this we can begin to understand
why for instance enhancing HTTP is easier than TCP, HTTP is mostly used for web exchanges while TCP is
a general protocol for reliable host-to-host communication. Hence due to TCP being a more fundamental
protocol, more systems will have to be involved in deploying a major change to TCP than HTTP echoing this
varying degree of ossification.</p>
<p><em>Figure 2: Increasing level of protocol ubiquity as you move down the protocol stack mirrors the degree of ossification</em></p>
<blockquote>
<p>Note:
Although it is true that application layer protocols are more flexible to developments
than lower layers mainly due to their existence in user-space rather than kernal
space, the increasing sophistication of middleboxes that tamper with higher layers
such as Layer-7 loadbalancers is spreading this phenomenon across the stack.</p>
</blockquote>
<p>Moving on from the general concept of protocol ossification, next we transition into the main focus of this post
which is the protocol ossification phenomenon specifically occurring at the transport layer ie Transport Layer
Ossification.</p>
<h3 id="22-transport-layer-ossification">2.2 Transport Layer Ossification</h3>
<p>As mentioned briefly above, TCP is a fundamental transport protocol for host to host communication. Evidently,
one of the most common questions that emerge when we think about system design is the choice between
using TCP and UDP as transport. More so the TCP/IP stack is nowadays synonymous with the internet because
almost every kernel in the world supports it hence if a given system wishes to communicate at global scale in
today’s networks it has to understand this stack.</p>
<p>With such enormous ubiquity at the transport layer, transport protocols have become foundational to network
communications and so changing them or replacing them is almost practically impossible leading to the
existence of Transport Layer Ossification which is what this blog post is all about. [link to paper (How practical
is it to make changes to TCP)]</p>
<h2 id="what-causes-such-a-phenomenon-to-exist">What causes such a phenomenon to exist?</h2>
<p>With the above in mind, how do middleboxes actually cause such a phenomenon ?
The way in which networks are governed is in some ways similar to how different states around the world
govern themselves, in different networks different policies are enforced where some are more restricted than
others. In such networks, strict policies are usually enforced for security and control reasons which often
translates to the deployment of highly sophisticated middleboxes (Proxies, Firewalls, IDS, IPS etc) that inspect
passing traffic and takes action based on the implemented polices.
So in order for middleboxes to be able to deeply inspect traffic to perform various impairments reflecting their
policy, such devices need to be sophisticated enough that they operate at layers further than the Network layer
as illustrated in figure X. This way, the described end-to-end approach discussed earlier is broken due to the
spread of sophisticated systems performing functions other what a standard IP router does across networks as
shown below and not just at the edge.</p>
<p><em>Figure 3: Distributed share of sophisticated systems across networks</em></p>
<p>We can elaborate further on how middleboxes result in such a protocol using the figure above. We observer
that the end system to the right has it’s traffic directed through a firewall that operates at the transport layer.
In other words the firewall inspects the visible headers at the transport layer and makes a decision either to
allow or deny passing traffic. On the other side, assuming that the traffic is coming from the left, the layer 7
loadbalancer could be put in place to distribute the traffic across the end systems behind it, thereby spreading
the traffic load. In the case of a HTTP exchange, the loadbalancer will inspect the incoming HTTP packets and
base its balancing decision on the HTTP headers such as the resource requested, request type, etc.</p>
<p>With such sophistication at the network core, protocol development have to take into account the support
of those systems to be functional today. Say that the end system to the right in the example above wishes to
establish a SCTP connection in the example above, but the firewall on path has based its rules on the most
commonly used transport protocols UDP and TCP. In this case the firewall is likely to block this traffic as it is
unable to understand it, this will likely be the case in more restricted networks.</p>
<p>Another example from the above would be regarding the layer 7 loadbalancer distributing HTTP traffic among
web servers. If a major change to the HTTP protocol is made that changes the header structure or adds
additional headers, without the support of the loadbalancer it will not be able to perform its loadbalancing
due to the unfamiliar HTTP header structure.</p>
<p>Consequently, the spread of intelligence across the core of networks makes it extremely hard to innovate
protocols and it only gets worse as more and more devices support these legacy protocols.
As a result of the situation described above, it natural to ask the simple question, why should we care? In the
following section I attempt to address a few of those concerns.</p>
<h2 id="4-why-protocol-ossification-is-a-problem-today">4 Why Protocol Ossification is a problem today?</h2>
<p>Over time, middleboxes develop assumptions and patterns on network traffic based on its observations at the
various protocol layers they inspect which is then classified to usual or unusual categories. Take for example
the TCP protocol, middleboxes have become accustomed to the frequent types of options that is typically seen
and as a result, in strict domains if two parties attempt to establish a TCP connection with a relatively new
or unusual option, it is likely that some middleboxes will intervene either to completely block or strip the
TCP option causing at least some added latency or more seriously a complete hault to the communication.
Examples of this has been studied by Korian Edeline and Benoit Donnet in their respective paper that looked
at the Multi-Path TCP (MPTCP) and the Selective Acknowledgements (SACK) TCP options that showed to
often experience impairments by middleboxes. After all, this makes it extremely hard to enhance such legacy
protocols.</p>
<p>Given that middleboxes develop such assumptions and enforce strict policies on passing traffic, this forces
applications to build on top of such ossified protocols just so that they can coexist with middleboxes. With the
distribution of control across the edge and centre of networksThis is an issue because such legacy protocols
were created when the internet was way less complex than it is today and therefore the abilities of such legacy
protocols fall short to fulfil the evolving requirements of modern networks.</p>
<p>A modern example of the above can be seen with the evolution of HTTP which I discuss in some detail here.
However in short, The ability of HTTP to enhance its performance to fit the needs of the modern web was
limited by it’s dependence on TCP at the transport layer. In the end the decision was to instead use UDP, a
lightweight transport layer protocol and implement the needed transport functions on top of that at a higher
level with QUIC (see figure x) freeing them from the performance latency’s of TCP’s legacy design.</p>
<h2 id="5-workarounds">5 Workarounds</h2>
<p>• End-to-End Encryption
exposure of packet headers is what enables middleboxes to ossify protocols and build assumptions, they
cant do that when unnecessary headers are encrypted.
As we know from foundational protocol studies, the lower we move down the protocol stack the closer we are
to the actual hardware. In this case if we observe the separation between the user and kernal space domains,
we see that it it traditionally lies between the transport and application layers.</p>
<p><em>Figure 4: Traditional protocol scope</em></p>
<p>From that we can make sense of transport layer protocols ubiquity and why they have been ossified over time.
The kernel space is typically where minimal core functions are implemented unlike user space where a much
larger variety of other operations reside. Therefore, protocols like TCP and UDP are implemented in kernel
space due to them being fundamental to network devices. And so if any developments are made to TCP they
have to be pushed to system kernels world-wide for the change to be operational globally.</p>
<p>This also explains why we tend to see new modifications of TCP implemented and developed for certain
domains such as Data Center TCP (DCTCP) which is a TCP version that is tailored for Data Center operations.
We dont see those versions deployed world wide for the reasons mentioned above and also for the simple fact
that sometimes it doesnt provide much benifit to the normal end user.</p>
<p>That being said, regardless of the fact that transport protocols have traditionally resided in kernel space, that
does not mean that certain transport functions cant be moved to the user space scope. And you might wonder
why would we be interested in that?</p>
<p>As we learn from QUIC and SCTP, the attempt to enhance TCP or develop a protocol from scratch (in kernel
space) that better fits the needs of today’s networks is almost impossible, thanks to middleboxes and the
complexity involved with making world-wide system kernels support this development. In QUIC’s case, in
order to bypass these limitations the solution involved another approach which was to build on top of an
already supported or for a better term ossified protocol in this case UDP.</p>
<p><em>Figure 5: Transport layer breakthrough from it’s traditional scope within the kernel space</em></p>
<p>What this does is it eliminates the challenge of attempting to coexist with middleboxes and moves the needed transport functions (congestion control, packet reordering etc) to user space where there is much more flexibility of deployment and support. With HTTP3, this approach is implemented where QUIC contains the
needed transport functions and assumes that the very lightweight transport protocol UDP is beneath it.</p>
<p><em>Figure 6: Difference between TCP and UDP Header Formats from RFCs 761 and 768</em></p>
<p>With that being said, it leads us to question the effectiveness of this workaround which I intend to explore in
the following.</p>
<ul>
<li>How effective is this workaround?</li>
<li>How will middleboxes act with more frequent UDP traffic (HTTP3, DNS-over-QUIC &hellip;)?</li>
<li>how easy is it to block QUIC?</li>
<li>best solution we have or are there others?</li>
</ul>
<p><em>Figure 7: Transport layer breakthrough from it’s traditional scope within the kernel space</em></p>
<h2 id="closing-remarks">Closing remarks</h2>
]]></content>
        </item>
        
        <item>
            <title>Dethroning TCP From The Web?</title>
            <link>http://localhost:1313/posts/dethroningtcpfromtheweb/</link>
            <pubDate>Sat, 23 Dec 2023 10:23:33 +0400</pubDate>
            
            <guid>http://localhost:1313/posts/dethroningtcpfromtheweb/</guid>
            <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Latest Revision: 27th of December&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h4&gt;
&lt;p&gt;The content of this post assumes knowlege of basic networking concepts such as the &lt;a href=&#34;https://en.wikipedia.org/wiki/OSI_model&#34;&gt;OSI&lt;/a&gt; model and how the &lt;a href=&#34;https://developer.mozilla.org/en-US/docs/Web/HTTP&#34;&gt;HTTP&lt;/a&gt; protocol works to fetch and serve web content.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Ever since Tim Burners-Lee created the World Wide Web, the Transport Control Protocol (TCP) has been the main and up until very recently, the most obvious option for transporting Hypertext Transfer Protocol (HTTP) web exchanges. Understandably, TCP was the transport protocol of choice given that the available options were limited between UDP and TCP, where UDP alone is a lightweight protocol that misses most of the features that the web desires.&lt;/p&gt;</description>
            <content type="html"><![CDATA[<blockquote>
<p><strong>Latest Revision: 27th of December</strong></p>
</blockquote>
<h4 id="prerequisites">Prerequisites</h4>
<p>The content of this post assumes knowlege of basic networking concepts such as the <a href="https://en.wikipedia.org/wiki/OSI_model">OSI</a> model and how the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP">HTTP</a> protocol works to fetch and serve web content.</p>
<hr>
<h2 id="introduction">Introduction</h2>
<p>Ever since Tim Burners-Lee created the World Wide Web, the Transport Control Protocol (TCP) has been the main and up until very recently, the most obvious option for transporting Hypertext Transfer Protocol (HTTP) web exchanges. Understandably, TCP was the transport protocol of choice given that the available options were limited between UDP and TCP, where UDP alone is a lightweight protocol that misses most of the features that the web desires.</p>
<p>Over 30 years have passed since the web was first available to the public domain and since then, it has evolved to become much more complex. Parallel to the increasing complexity of the web, the HTTP underwent several revisions (HTTP/1.0, HTTP/1.1, HTTP/2, and lately HTTP/3 ) for simplicity we will refer to them as H1.0, H1.1, H2 &amp; H3. TCP on the other hand, a much older protocol, relatively remained unchanged and only had minor tweaks over the years for reasons that will be elaborated further in the coming sections.</p>
<p>Regardless of this fact, TCP proved to work well overall in the web domain for so many years that to this day, web traffic mostly continues to use it as transport. Nevertheless, the evolution of the HTTP protocol across its revisions eventually emphasized major flaws with TCP that led to its complete replacement from the HTTP protocol stack. Most recently, H3 officially marked a new era for web transport where TCP, the transport protocol previously synonymous with the web, is replaced with QUIC.</p>
<p>As with every new technology, we are typically only exposed at first to its marketing, design and promises but eventually, what matters is how it performs. In an effort to answer this post’s title, the following text will first go through the context that led to where we are today with QUIC, then briefly discuss QUIC’s design, and lastly, the extent to which the promises are projected into practice and what that means for the future of the web.</p>
<h2 id="background">Background</h2>
<h3 id="uncovering-tcps-limitations">Uncovering TCP&rsquo;s limitations</h3>
<p>In the early days of the web, there were relatively few requests occurring in a single web transaction, sometimes a single HTTP request to fetch the HTML page is all that was needed to take place. Web pages were much simpler than what we see nowadays and as a result, early HTTP versions were sufficient for that purpose. However, if we look at how HTTP worked in early versions and continued to evolve, we can understand how future requirements of the web could not be fulfilled by the same underlying technologies. In the following subsections, HTTP’s evolution is explained to establish a better understanding of how we got to this stage.</p>
<h4 id="http10">HTTP/1.0</h4>
<p>H1 was the first HTTP version standardized by the Internet Engineering Task Force (IETF) in 1995. The specifications of how web exchanges operate are illustrated in the figure below.</p>
<p><img alt="HTTP/1.0" src="/img/HTTP1_0_Sequence.drawio.png">
<em>Fig 1: Timeline illustrating a H1.0 exchange, note that the TCP connection only serves a single HTTP request.</em></p>
<p>As presented above, in a typical H1.0 exchange, a TCP connection is established to facilitate the transport of a single HTTP exchange (HTTP Request &amp; Response) and then immediately terminated. This means that for every HTTP exchange the client will need to establish a new TCP connection with the server which does not seem effective nevertheless, it was sufficient enough for fetching simple static sites in the early days of the web. However, it is obvious how limited and unscalable this approach becomes if more HTTP exchanges are to take place. Hence, the arrival of H1.1 just a year later.</p>
<h4 id="http11">HTTP/1.1</h4>
<p>What H1.1 mainly aimed to achieve was the ability to consume TCP connections more efficiently, specifically by exchanging multiple HTTP exchanges per TCP connection as illustrated in the diagram below. This approach was instantly more effective than H1.0 since TCP connections are now kept “alive” until all needed HTTP exchanges are completed.</p>
<p><img alt="HTTP/1.1" src="/img/HTTP1_1_Sequence.drawio.png">
<em>Fig 2: H2 allows for multiple requests to be sent in the same TCP connection.</em></p>
<p>More so, this version of HTTP introduced the concept of <em>Pipelining</em> which allows the client to send subsequent HTTP requests without needing to wait for each corresponding response to be processed. This also led to notable performance improvements since in previous versions, subsequent requests could not be sent until the response of the previous request has been received and processed.</p>
<p>Nevertheless, H1.1 still left room for improvement. Mainly in the fact that from the server’s perspective, responses are not sent until all prior requests are processed. For example in the figure above, even though request #1 arrives first, it is not responded to until request #3 has been processed. This is not ideal in the web domain as some requests can be unrelated to others and for that reason, they should not be slowed down by later requests.</p>
<p>To get around this issue, specifications suggested that clients can establish up to 6 TCP connections with a server as shown in figure 3. This way, subsequent requests can be assigned a dedicated TCP connection, which will make HTTP requests sent in different TCP connections independent of the rest allowing the server to respond to them faster.</p>
<p><img alt="HTTP/1.1 6 TCP Connections" src="/img/6TCPStreams.drawio.png">
<em>Fig 3: H1.1 client can establish six TCP connections to enable the receiver to respond independently to the transmitted data in each connection.</em></p>
<p>This however was not an efficient solution mainly because of the high resources that servers require to maintain up to 6 TCP connections per client. Despite the inefficiency in this regard, H1.1 worked well and was not succeeded until about a decade later. The arrival of H2 enhanced the performance and efficiency of web exchanges but also shed light to major TCP limitations that eventually led to the development of QUIC.</p>
<h4 id="http2">HTTP/2</h4>
<p>Working around the previous version’s limitations, H2 implemented the concept of <em>Multiplexing</em> that introduced independent streams for HTTP exchanges that can share a single TCP connection. This way HTTP exchanges can be processed independently without the need to establish multiple TCP connections as done in H1.1.</p>
<p><img alt="HTTP/2" src="/img/HTTP2_Sequence.drawio.png">
<em>Fig 4: H2 requests can be uniquely identified allowing the server to respond to them independently.</em></p>
<p>Nevertheless, the performance benefits of H2 could not be fully realised due to TCP’s byte-stream view of data that it receives from other layers. This means that data in independent H2 streams at the application layer will be interpreted as a whole stream of bytes by TCP at the transport layer as shown in the following diagram.</p>
<p><img alt="TCP&rsquo;s stream perspective" src="/img/HTTP2HOF.drawio.png">
<em>Fig 5: The H2 streams are treated as a single stream of bytes at the transport layer.</em></p>
<p>The important aspect to grasp from the illustration above is how the three independent HTTP streams (A, B &amp; C) are batched together and sent in-flight as a single stream of bytes at the transport layer, where in the case that a byte in that stream is lost, the entire stream awaits re-transmission before being processed at the receiver. This behavior is referred to as <em>Head-of-Line Blocking</em>. Ultimately, this observation highlights an important performance bottleneck:</p>
<blockquote>
<p>To fully reap the benefits of multiplexing at the application layer (which is what H2 did by introducing streams), multiplexing must also be supported at the transport layer.</p>
</blockquote>
<p>At this stage, we can begin to see that for the web to continue to enhance its performance, the focus needs to shift from the application layer to the transport layer specifically TCP which is where the main limitation lies. To address this limitation, the potential solutions were mainly among two pathways:</p>
<ol>
<li>
<p>Improve TCP’s implementation so that multiplexing is supported at the transport layer.</p>
</li>
<li>
<p>Develop a new protocol that will understand the concept of streams therefore supporting multiplexing and have it use UDP as a substrate (for reasons explained in the following).</p>
</li>
</ol>
<p>It might first seem that enhancing an established protocol is a more efficient and reasonable solution rather than developing one from scratch. However in this case it is the opposite. TCP is a kernel-side protocol that has been used in the internet for over 40 years, to introduce a major change to such an established protocol would practically mean changing TCP’s implementation in major kernel vendors. This would also include deploying changes to <em>Middleboxes</em> across the internet and not just end-systems which is simply not practical in today’s networks. More so, even if global scale support was initiated, it will take years to see wide-scale deployment which doesn’t match the rate at which the web is evolving. This challenge that stagnates the enhancements of a protocol is sometimes referred to as <em>Protocol Ossification</em> which is a topic worthy of its own post.</p>
<p>Eventually, the second pathway prevailed as a more practical option that involves having our desired features like multiplexing, implemented on top of a lightweight established transport protocol like UDP to avoid stagnant compatibility efforts.</p>
<h3 id="emergence-of-quic">Emergence of QUIC</h3>
<p>Development efforts kicked off at Google around 2012 to develop a new protocol which we know today as QUIC. Initially, the focus was on developing a multiplexed transport protocol that will help boost HTTP’s performance potential. Later in 2015, the QUIC efforts at Google were passed to the Internet Engineering Task Force (IETF) which desired to make QUIC an independent transport protocol that can benefit other application layer protocols and not just HTTP.</p>
<blockquote>
<p>It is important to highlight that when talking about “QUIC” we are typically referring to the standardized version of QUIC that occupies the content of RFC 9000. Where as the initial implementation of QUIC that was developed at Google is known as <em>gQUIC</em>. There are differences between the two implementations however, after the migration to the IETF, Google also worked to tune their implementation to support the standardised QUIC specifications.</p>
</blockquote>
<p>Although QUIC is a “transport protocol”, it resides in user-space unlike traditional transport protocols such as TCP &amp; UDP. As mentioned earlier, this is a workaround for the ossified transport layer to allow QUIC as a protocol to evolve in the future with ease.</p>
<p><img alt="QUIC Protocol Stack" src="/img/quicstack.jpg">
<em>Fig 6: QUIC’s protocol stack highlighting the user-kernel space division.</em></p>
<p>QUIC at first seems like a new protocol that is just TCP with multiplexing, but that is not entirely the case. It was also equipped with a set of features that can enhance the experience of web clients. The following is a brief overview of some of those features:</p>
<ol>
<li>Reduced Connection Handshake Latency</li>
</ol>
<p>A significant part of the web experience is related to the time it takes to establish a connection with servers because that determines how fast can we start sending application data. Especially nowadays where it is likely that even the contents within a single web page will be served from varying locations, a client can be expected to require establishing multiple connections while surfing the web. In this regard, QUIC costs at most a single round trip before being able to send application data whereas with TCP, it takes a couple of round trips (could be more if TLS 1.2 or an older version is being used).</p>
<p><img alt="QUIC Handshake" src="/img/quichandshake.jpeg">
<em>Fig 7: Comparing handshakes of TCP (with TLS 1.3) against QUIC’s handshake that requires fewer round trips [1].</em></p>
<ol start="2">
<li>Zero Round Trip Time (0-RTT)</li>
</ol>
<p>As described above, QUIC takes a single round trip at most but in certain cases QUIC also can allow clients to send application data from the start before receiving anything from the server. This does however require the client to have either had a previous connection to this server or set predefined configurations.</p>
<ol start="3">
<li>Connection Migration</li>
</ol>
<p>Unlike with TCP, a QUIC connection is not dependent on the IP of the client device. Meaning if for instance, a client switches from Wi-Fi to a mobile network midway through a QUIC connection, that connection will be carried over and not terminated. Typically with TCP, if the IP address changes, the connection will close and have to be re-established.</p>
<p><img alt="QUIC CIDs" src="/img/quiccid.png">
<em>Fig 8: Illustration showing how Connection IDs (CID) is negotiated between the client and server to avoid having to open a new connection if the client changes network [4].</em></p>
<p>The above are just a few of the main additional features of QUIC that were put in place to improve the experience of low-latency demanding services and cases where the client’s underlying network may change. QUIC also built on years of experience with testing TCP and enhancing aspects of transport functions like loss-recovery, congestion control and others. Fundamentally, QUIC offers a lot more than what will be covered here (see <a href="https://datatracker.ietf.org/doc/rfc9114/">RFC9000</a>) to avoid dragging this post longer than desired.</p>
<p>Focusing on the most relevant feature of QUIC to this post, the following diagram illustrates how it is designed to be capable of multiplexing at the transport layer. When each of the HTTP streams is passed down to QUIC, independent QUIC <em>Streams</em> are assigned at the transport layer. This then enables the receiving end to distinguish between the incoming streams of bytes and consequently, be able to process and pass them to the application independently as soon as they arrive, thereby achieving the benefits of multiplexing. Comparing this to the previous example in H2, QUIC can assign each of the images an independent stream and so if one stream relating to image A is affected, only the processing of that stream awaits retransmission while streams of image B and C are processed therefore avoiding the head-of-line blocking problem with TCP.</p>
<p><img alt="QUIC Streams" src="/img/quicstreams.png">
<em>Fig 9: QUIC streams are uniquely identified at both ends enabling the server to handle each request independently of the state of the others.</em></p>
<blockquote>
<p>Importantly note that in this case UDP being a well established protocol, simply acts as a vehicle for QUIC to traverse the internet infrastructure. After all, UDP operates as usual in a “best-effort” manner while all the other desired features for web exchanges (retransmission, packet reordering and other) are delegated to QUIC. Unlike with TCP, UDP does not interfere with QUIC’s streams by not interpreting them as a single stream of bytes.</p>
</blockquote>
<p>With that capability to multiplex at the transport layer, H3 is now officially a standard protocol <a href="https://datatracker.ietf.org/doc/rfc9114/">RFC 9114</a> that swaps out TCP from the HTTP protocol stack for QUIC and UDP.</p>
<p>Okay, all this theory sounds great but how does QUIC perform in the real world?</p>
<h2 id="performance-tests">Performance Tests</h2>
<p>Fortunately, QUIC has been around for some good time now and a decent amount of tests have been conducted to investigate QUIC’s performance in practice. In the following text, several distinct studies and experiments will be discussed listing their main observations.</p>
<p>To begin with, one of the early studies testing QUIC’s performance as expected came from Google in 2017 [3] and compared H3’s performance against H2 on metrics such as video rebuffer rates, video playback &amp; search latency leading to the following observations:</p>
<ul>
<li>
<p>As expected, QUIC outperformed TCP with handshake latency since it takes fewer round trips to complete. However, it is important to note here that the margin of improvement also increases as the minimum Round Trip Time (RTT) increases. This means that for connections where the RTT is relatively large, the performance improvement due to the shorter handshake is more noticeable.</p>
</li>
<li>
<p>In terms of search latency (the time from entering a search term till all the results are loaded), H3 outperforms H2 which is also attributed to the reduced handshake latency that does factor in this metric since connection establishment is part of fetching the search results. Here the improvement margin also increases as the RTT does.</p>
</li>
<li>
<p>Using QUIC, Video Latency (the time from selecting a video till the start of the video) and Video Rebuffer Rate are reduced. The first is also impacted by QUIC’s low handshake latency and the 0-RTT feature which the study claims that around 85% of connections to YouTube benefited from. The latter is insensitive to handshake latency and more attributed to QUIC’s more resilient loss-recover mechanism.</p>
</li>
<li>
<p>QUIC performed equivalently to TCP and sometimes worse in high bandwidth connections which was attributed to client-side CPU limitations. QUIC clearly showed to benefit high-loss &amp; high-delay networks showing significant improvements against TCP in locations like India that have the highest RTT and retransmission rates.</p>
</li>
<li>
<p>Running QUIC was in some cases consuming CPU resources 3.5x what TCP recorded due to it running in user-space.</p>
</li>
</ul>
<p>Building on the last observation above, another notable experimentation came from Fastly in 2020 [2] looking at QUIC’s computational cost which has been known for a while to be one of QUIC’s major drawbacks. The experiment looks at various approaches in which this computational cost can be minimised in comparison to TCP. They outline the following findings.</p>
<ul>
<li>
<p>QUIC is typically much more consuming of CPU resources due to residing in user-space nevertheless, there are possible tweaks that when implemented together can make QUIC almost as computationally costly as TCP. The main bottlenecks and workarounds for QUIC’s computational inefficiency are covered below:</p>
<ol>
<li>High number of Context Switches</li>
</ol>
<p>Due to QUIC’s transport logic residing in user-space, typically every QUIC packet needs to be passed between the user &amp; kernel space through a context switch.</p>
<p>Workaround: UDP Generic Segmentation Offloading (GSO).</p>
<p>GSO offers a way for a user-space app to coalesce QUIC packets and pass them together to the kernel as a single virtual packet to reduce the number of context switches required. So say we have 20 QUIC packets that need to be sent across, instead of needing 20 context switches (1 context switch per packet) we can group 10 packets and pass them over once, ultimately needing a total of 2 context switches (1 context switch per 10 packets).</p>
<ol start="2">
<li>Acknowledgment Rates</li>
</ol>
<p>TCP handles all acknowledgments (ACKs) logic at the kernel, QUIC on the other hand takes care of that also in the user space. The higher the acknowledgment rate the more data copies are needed.</p>
<p>Workaround: Delaying ACK rates per received packets.</p>
<p>QUIC specifications suggest that an ACK is sent per two received packets, this experiment has shown that reducing the ACK rate to one per 10 received packets has notably reduced computational overhead. Note that this workaround can have undesired consequences such as reducing the connection’s throughput.</p>
<ol start="3">
<li>Packet Sizes</li>
</ol>
<p>A small packet size would mean more packets are needed to transfer a piece of data which subsequently increases the required number of context switches as described in the first point.</p>
<p>Workaround: Increase packet size to reduce the total number of packets sent in a QUIC exchange (preferably set the packet size according to the received packet size from the sender to avoid getting dropped due to path limits).</p>
</li>
</ul>
<p>Lastly, a study from Brown University [5] investigated the performance of production QUIC among a few large-scale implementers (Google, Facebook &amp; Cloudflare). This particular study focused on investigating the root causes behind QUIC’s performance enhancements and also comparing the performances among the implementers in which they observed the following:</p>
<ul>
<li>
<p>QUIC’s low latency handshake &amp; 0-RTT provide notable performance enhancements for small payloads only and are not the focal source of improvement over TCP implementations. With larger payloads (over 100KB), QUIC’s performances are almost equivalent to TCP and could be worse depending on the choice and implementation of the congestion controller.</p>
</li>
<li>
<p>The implementation of the congestion control algorithm majorly impacts QUIC’s performance. This means that implementers using the same congestion control algorithm i.e. Cubic or BBR, may still extract significantly different performance results if their implementations are not alike.</p>
</li>
<li>
<p>QUIC’s design which allows for flexible implementation leads to significant inconsistencies in performance between implementers.</p>
</li>
</ul>
<p>Keeping the above in mind, how does the future of the web look like with QUIC in play and what does it mean for implementations still using TCP as transport in the web domain?</p>
<h2 id="concluding-thoughts">Concluding Thoughts</h2>
<p>In summary, the web’s increasing performance demands have shed light on various drawbacks of TCP. Coupled with the challenges of the ossified transport layer, how we implement transport functions has changed notably. Embodied in QUIC, transport functions are moved to the userspace while using UDP to traverse the current infrastructure. With the standardization of H3, TCP is no longer the obvious option of transport for web exchanges. Ultimately, looking at what we know today about QUIC and how it performs in production, the following are my concluding remarks concerning where QUIC and the web domain are heading.</p>
<ol>
<li>Overall QUIC achieves what it was designed to do and produces impressive results for latency-sensitive services.</li>
</ol>
<p>On average, QUIC outperforms TCP implementations and although this improvement can be minimal in high-bandwidth networks, the margin of improvement is significant in high-loss/delay conditions. This enhances the experience of web clients in many parts of the world that do not benefit from high-quality networks that previously suffered due to depending on an ossified legacy technology like TCP.</p>
<ol start="2">
<li>QUIC’s computational cost will likely remain higher than TCP as long as it resides in user space.</li>
</ol>
<p>There isn’t a reliable &amp; consistent solution to QUIC’s computational inefficiency than to have it implemented in the kernel. The workarounds attempted by Fastly have shown promising results but the proposed modifications themselves are only applicable to varying degrees depending on either the client, server or network capabilities. For example, increasing packet sizes depends on path limitations which can differ from one client to another, the higher the packet size the greater the risk of it getting dropped. Additionally, delaying ACKs has been shown to reduce QUIC’s computation but it can also lead to reducing a connection’s throughput which will subsequently affect the performance. Eventually, such workarounds come with tradeoffs and do not promise consistent results.</p>
<p>Although implementing QUIC in the kernel is technically possible, it is not so practical or feasible at least at this point. As mentioned in earlier sections, bringing a major change to the transport layer is a challenging task, due to the global and ubiquitous effort that is required and also the strong use case that QUIC currently lacks. Even though QUIC has shown great improvements over TCP implementations, the change is not crucial. Just to draw a parallel, the use case for supporting IPv6 globally (to resolve IPv4 exhaustion) is stronger than it is to support QUIC and as I write this post, IPv4 still dominates the internet over 25 years since the first specifications were published. I’m not saying QUIC will require as much time but regardless it will take a considerable amount of time and effort.</p>
<ol start="3">
<li>The QUIC protocol remains in its early days and the current discrepancy in its performance will reduce over time.</li>
</ol>
<p>QUIC’s flexibility has its pros and cons, the cons as noted above lead to varying performance results between implementers, even those using the same configurations and choice of congestion control algorithms. The pros are that QUIC is relatively still in its early days and fine-tuning it is practical. The current open-source and from-scratch implementations of QUIC will over time become battle-tested and normally, such implementations will change to become more unified as we learn more about the protocol’s behavior in production environments.</p>
<ol start="4">
<li>TCP is nowhere to go in the web domain.</li>
</ol>
<p>Finally, despite QUIC’s promising performance gains and adoption so far, it’s really difficult to see TCP implementations reducing drastically in the web domain, especially in the short term. TCP is a robust battle-tested protocol that continues to serve the majority of web traffic. Even today, it is typical for QUIC clients to fall back to TCP when issues are encountered. Ultimately, QUIC will remain a novel and viable option for services not just on the web front but TCP is here to stay.</p>
<hr>
<h2 id="references">References</h2>
<ol>
<li>
<p>Iyengar, Jana. Modernizing the internet with HTTP/3 and QUIC, 30 January 2020, <a href="https://www.fastly.com/cimages/6pk8mg3yh2ee/4AbXvmMTnu0kCc8t1063Zx/c878838fe1fdeff64761dba1a4387d3f/quic-image1.jpg?auto=avif">https://www.fastly.com/cimages/6pk8mg3yh2ee/4AbXvmMTnu0kCc8t1063Zx/c878838fe1fdeff64761dba1a4387d3f/quic-image1.jpg?auto=avif</a>.</p>
</li>
<li>
<p>Iyengar, Jana, and Kazuho Oku. “QUIC VS TCP: Which Is Better?” Fastly, 30 Apr. 2020, <a href="https://www.fastly.com/blog/measuring-quic-vs-tcp-computational-efficiency">www.fastly.com/blog/measuring-quic-vs-tcp-computational-efficiency</a>.</p>
</li>
<li>
<p>Langley, Adam, et al. &ldquo;The quic transport protocol: Design and internet-scale deployment.&rdquo; Proceedings of the conference of the ACM special interest group on data communication. 2017.</p>
</li>
<li>
<p>Marx, Robin. How QUIC Helps You Seamlessly Connect to Different Networks. Pulse, 4 July 2023, <a href="https://pulse.internetsociety.org/wp-content/uploads/2023/06/3-migration-multi-cid.png.s">https://pulse.internetsociety.org/wp-content/uploads/2023/06/3-migration-multi-cid.png.s</a></p>
</li>
<li>
<p>Yu, Alexander, and Theophilus A. Benson. &ldquo;Dissecting performance of production QUIC.&rdquo; Proceedings of the Web Conference 2021. 2021.</p>
</li>
</ol>
]]></content>
        </item>
        
    </channel>
</rss>
